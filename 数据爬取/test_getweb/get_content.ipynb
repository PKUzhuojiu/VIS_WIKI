{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取历史条目``edit_history.csv``之后，用本程序获取每次编辑后页面的内容\n",
    "\n",
    "这里爬取了每个页面源码中id为bodyContent的部分，结果保存在webcontent文件夹内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to get page, id: 3887, url_id: 996604907\n",
      "succeed to get page 3887!\n",
      "try to get page, id: 3888, url_id: 996478192\n",
      "succeed to get page 3888!\n",
      "try to get page, id: 3889, url_id: 996477549\n",
      "succeed to get page 3889!\n",
      "try to get page, id: 3890, url_id: 996476036\n",
      "succeed to get page 3890!\n",
      "try to get page, id: 3891, url_id: 996465717\n",
      "succeed to get page 3891!\n",
      "try to get page, id: 3892, url_id: 996465335\n",
      "succeed to get page 3892!\n",
      "try to get page, id: 3893, url_id: 996456871\n",
      "succeed to get page 3893!\n",
      "try to get page, id: 3894, url_id: 996454523\n",
      "succeed to get page 3894!\n",
      "try to get page, id: 3895, url_id: 996453669\n",
      "succeed to get page 3895!\n",
      "try to get page, id: 3896, url_id: 996452840\n",
      "succeed to get page 3896!\n",
      "try to get page, id: 3897, url_id: 996448243\n",
      "succeed to get page 3897!\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import unicodedata\n",
    "import numpy\n",
    "\n",
    "# edit_history.csv保存了所有历史编辑页面的id，通过这个id可以获取到历史页面的链接，也即是urlhead+oldid\n",
    "# 每次爬取时，先确定要爬取的页面id范围，下面是edit_history.csv的第1到第2个id的示例代码\n",
    "# 需要修改的地方有：\n",
    "# 1. start_row, max_row 起止id的索引\n",
    "# 2. urlhead title修改成目标词条\n",
    "# 3. proxies修改成自己的代理\n",
    "\n",
    "\n",
    "urlhead = \"https://en.wikipedia.org/w/index.php?title=Donald_Trump&oldid=\" # 请修改\n",
    "\n",
    "s = rq.session()\n",
    "s.proxies = {\"https\": \"127.0.0.1:1080\"}  # 修改成自己的代理\n",
    "s.keep_alive = False\n",
    "\n",
    "max_row = 3897#7610 # 请修改\n",
    "start_row = 3887#3834 # 请修改\n",
    "\n",
    "with open('edit_history_trump.csv', 'r', encoding='utf-8') as f1:\n",
    "    rows = csv.reader(f1)\n",
    "    for row in rows:\n",
    "        id = int(row[0])\n",
    "        if id < start_row:\n",
    "            continue\n",
    "        if id > max_row:\n",
    "            print('finish')\n",
    "            break\n",
    "        page_oldid = str(row[1])\n",
    "        print(f'try to get page, id: {id}, url_id: {page_oldid}')\n",
    "        page_link = urlhead + page_oldid\n",
    "        try:\n",
    "            r = s.get(page_link, timeout=60)\n",
    "            r.encoding = 'utf-8'\n",
    "            soup = BeautifulSoup(r.text, 'lxml')\n",
    "            dateDOM = soup.find('span', id='mw-revision-date')\n",
    "            revdate = dateDOM.get_text()\n",
    "            with open(f'./webcontent/data/{id}'+'.txt', 'w', encoding='utf-8') as f2:#content_{id}_{page_oldid}'+'.txt', 'w', encoding='utf-8') as f2:\n",
    "                body = soup.find('div', id='bodyContent')\n",
    "                f2.write(f'{str(id)} {str(page_oldid)} {revdate}\\n')\n",
    "                f2.write(str(body))\n",
    "                print(f'succeed to get page {id}!')\n",
    "        except:\n",
    "            print(f'fail to get page {id}!')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "407730e7b1f53fc8a0b1d9241751e40cdef0af9ebe90eb3a995d30f08872e3ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
